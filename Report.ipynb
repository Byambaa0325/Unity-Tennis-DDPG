{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition of Multiple Agents\n",
    "\n",
    "---\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net with a goal to not drop the ball. \n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "**Unity Machine Learning Agents (ML-Agents)** is an open-source Unity plugin that enables games and simulations to serve as environments for training intelligent agents. It has myriads of environments up for a challenge, and in which the environment we will be solving during this project is **Tennis**.\n",
    "![image.png](https://video.udacity-data.com/topher/2018/May/5af7955a_tennis/tennis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an agent hits the ball over the net, it receives a reward of +0.1. If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01. Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "Let's start by installing all the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is provided and can be accessed at the file path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Each agent receives its own, local observation. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Total states shape: (2, 24)\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape\n",
    "print('There are {} agents. Total states shape: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is episodic, and in order to solve the environment, your agents must get an average score of +0.5 (over 100 consecutive episodes, after taking the maximum over both agents). Specifically,\n",
    "\n",
    "- After each episode, we add up the rewards that each agent received (without discounting), to get a score for each agent. This yields 2 (potentially different) scores. We then take the maximum of these 2 scores.\n",
    "- This yields a single score for each episode.\n",
    "\n",
    "The environment is considered solved, when the average (over 100 episodes) of those scores is at least +0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "Lets take look at using the Python API to control the agent and receive feedback from the environment. We will run a single episode with a RandomAgent who takes actions randomly.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: 0.04500000085681677\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DDPG Agent Solver\n",
    "\n",
    "The environment is continuous environment which has state space and action space that are both continuous. As such, we would need an agent that can deal with continuous setting. Here **DDPG** algorithm comes to the rescue. Unlike our **DQN** algorithm that is a Q-learning variant which uses deep neural network to approximate the Q-function, **DDPG** also learns policy at the same time as learning Q-function. Therefore, it is a mix between Q-learning and Policy Gradient methods.\n",
    "\n",
    "![image.png](https://spinningup.openai.com/en/latest/_images/math/5811066e89799e65be299ec407846103fcf1f746.svg)\n",
    "\n",
    "The reason for choosing **DDPG** is because it is, in a nutshell, **DQN** for continuous action spaces. If you recall, **DQN** deals with environments with discrete action spaces like pressing buttons while **DDPG** can tell how hard to press that button. As same as **DQN**, it uses: \n",
    "\n",
    "- Replay Buffers\n",
    "- Target Networks\n",
    "\n",
    "The main addition is using calculating the max over actions in the target:\n",
    "![equationDDPG.png](https://spinningup.openai.com/en/latest/_images/math/4421120861d55302d76c7e2fd7cc5b2da7aea320.svg)\n",
    "Computing the maximum over actions in the target is a challenge in continuous action spaces. DDPG deals with this by using a target policy network to compute an action which approximately maximizes the Q network.\n",
    "\n",
    "While I won't go deep down to the details DDPG algorithm, I'll guide you to great resources that does a much better job at explaining it than I would here :)\n",
    "\n",
    "- [The original paper introducing the DDPG](https://arxiv.org/abs/1509.02971)\n",
    "- [DDPG implementation by Spinning Up, OpenAI](https://spinningup.openai.com/en/latest/algorithms/ddpg.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementation Details\n",
    "\n",
    "The **DDPG** agent that we will use to solve the environment will be a modified **DDPG** algorithm.\n",
    "\n",
    "#### Hyperparaments\n",
    "Note that the hyper parameters used for the training was:\n",
    "    - n_episodes = 2000\n",
    "        Train for total of 2000 episodes until the environment is solved\n",
    "    - max_t = 1000 \n",
    "        Maximum of 1000 timesteps per episode\n",
    "    - start_steps = 100\n",
    "        Randomly sample actions for 100 episodes to encourage exploration at the start of the learning process\n",
    "    - learn_frequency = 10\n",
    "        Learn per 10 timesteps when training.\n",
    "    - learn_count = 5\n",
    "        Learn 5 times at the learning step\n",
    "        \n",
    "#### Neural network inside the agent\n",
    "\n",
    "The **Actor** neural network inside the agent is simple shallow network with 3 linear layers with a batch norm within them.\n",
    "\n",
    "    State value -> \n",
    "    LinearLayer(state size, 400) -> Relu ->\n",
    "    BatchNorm1d(400) -> \n",
    "    LinearLayer(400, 300) -> Relu ->\n",
    "    BatchNorm1d(400) -> \n",
    "    LinearLayer(300, action size) ->\n",
    "    Action values\n",
    "\n",
    "The **Critic** neural network inside the agent is simple shallow network with 3 linear layers with a batch norm within them.\n",
    "    \n",
    "    State value -> \n",
    "    Linear(state_size, 400) -> Relu ->\n",
    "    BatchNorm1d(400) -> \n",
    "    Linear(400+action_size, 300) -> Relu ->\n",
    "    Linear(300, 1) -> \n",
    "    Q-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Implementation\n",
    "\n",
    "Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function seperate global observation to local observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_states(states):\n",
    "    return states[:1], states[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to process state by each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_actions(states, agent, add_noise):\n",
    "    state_0, state_1 = get_states(states)\n",
    "    action_agent_0 = agent.act(state_0, add_noise)\n",
    "    action_agent_1 = agent.act(state_1, add_noise)\n",
    "    return np.concatenate((action_agent_0, action_agent_1), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DDPG** learning algorithm that uses single agent to emulate multi-agent behaviour. Algorithm receives global observation for 2 agents and must send action signal for each agent in total of 2. However, the trick is to emulate self-play behaviour with a single DDPG Agent. \n",
    "\n",
    "The self-play part comes in as a single DDPG agent decides actions of two agents in the environment and learns from the experiences of both. Therefore, it plays with it self essentially. The agent gradually learns to play better and better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ddpg(n_episodes=500, max_t=1000, start_steps = 10, learn_frequency = 20, learn_count = 10, random_seed = 1):\n",
    "    \"\"\"Deep Deterministic Policy Gradient (DDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int)      : maximum number of training episodes\n",
    "        max_t (int)           : maximum number of timesteps per episode\n",
    "        start_steps (int)     : number of starting steps actions are chosen randomly \n",
    "        learn_frequency (int) : frequency of learning per timestep\n",
    "        learn_count (int)     : number of learning steps to do at learning timestep\n",
    "        random_seed (int)     : random seed for agent's weights \n",
    "    \"\"\"\n",
    "        \n",
    "    agent = Agent(state_size=state_size, action_size=action_size, random_seed=random_seed)   #Initialize the Agent\n",
    "    \n",
    "    avg_scores_episode = []                    # list containing scores from each episode\n",
    "    avg_scores_moving = []                     # list containing avg scores from window at each episode\n",
    "    scores_window = deque(maxlen=100)          # last 100 scores                    \n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]       # reset environment\n",
    "        states = env_info.vector_observations                   # get current state for each agent      \n",
    "        scores = np.zeros(num_agents)                           # initialize score for each agent\n",
    "        agent.reset()                                           # reset noise of the agent\n",
    "\n",
    "        for t in range(max_t):\n",
    "            #Randomly sample actions during the starting steps\n",
    "            if i_episode <= start_steps:\n",
    "                actions = np.random.randn(num_agents, action_size) # select an action randomly\n",
    "                actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "            else:\n",
    "                actions = agent.act(states, add_noise=True)     # select an action according to policy (for each agent)\n",
    "            env_info = env.step(actions)[brain_name]            # send actions to environment\n",
    "            next_states = env_info.vector_observations          # get next state (for each agent)\n",
    "            rewards = env_info.rewards                          # get reward (for each agent)\n",
    "            dones = env_info.local_done                         # see if episode has finished (for each agent)\n",
    "            \n",
    "            # for each agent's experience, save it and learn\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                if t % learn_frequency == 0: # Learn with frequency\n",
    "                    agent.step(state, action, reward, next_state, done, learn = True, learn_count = learn_count)\n",
    "                else:\n",
    "                    agent.step(state, action, reward, next_state, done, learn = False) #just add, don't learn\n",
    "                    \n",
    "            states = next_states\n",
    "\n",
    "            scores += np.max(rewards)                           # add the rewards from the timestep to the scores\n",
    "            if np.any(dones):                                   # finish episode if any agent has reached a terminal state\n",
    "                break\n",
    "\n",
    "                \n",
    "        scores_window.append(np.max(scores))            # save the most recent score to scores window\n",
    "        \n",
    "        avg_scores_episode.append(np.max(scores))       # save the most recent score to avg_scores\n",
    "        avg_scores_moving.append(np.mean(scores_window)) # save the most recent score window average to moving averages\n",
    "\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 1 == 0: # Print every episode\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f} \\t Current Score: {:.2f}'.format(i_episode, np.mean(scores_window), np.mean(scores)))\n",
    "            \n",
    "        #environment is solved\n",
    "        if np.mean(scores_window)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.actor_local.state_dict(), \"checkpoint_actor.pth\")        #Save actors' weights\n",
    "            torch.save(agent.critic_local.state_dict(), \"checkpoint_critic.pth\")      #Save critics' weights\n",
    "            break\n",
    "            \n",
    "    return avg_scores_episode, avg_scores_moving # Return average score of each episode and moving average at that time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the agent until it solves the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 2\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 3\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 4\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 5\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 6\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 7\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 8\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 9\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 10\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 11\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 12\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 13\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 14\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 15\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 16\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 17\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 18\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 19\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 20\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 21\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 22\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 23\tAverage Score: 0.01 \t Current Score: 0.20\n",
      "Episode 24\tAverage Score: 0.02 \t Current Score: 0.10\n",
      "Episode 25\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 26\tAverage Score: 0.02 \t Current Score: 0.10\n",
      "Episode 27\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 28\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 29\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 30\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 31\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 32\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 33\tAverage Score: 0.02 \t Current Score: 0.10\n",
      "Episode 34\tAverage Score: 0.02 \t Current Score: 0.10\n",
      "Episode 35\tAverage Score: 0.03 \t Current Score: 0.30\n",
      "Episode 36\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 37\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 38\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 39\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 40\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 41\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 42\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 43\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 44\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 45\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 46\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 47\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 48\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 49\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 50\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 51\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 52\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 53\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 54\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 55\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 56\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 57\tAverage Score: 0.03 \t Current Score: 0.20\n",
      "Episode 58\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 59\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 60\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 61\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 62\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 63\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 64\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 65\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 66\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 67\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 68\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 69\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 70\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 71\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 72\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 73\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 74\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 75\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 76\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 77\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 78\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 79\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 80\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 81\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 82\tAverage Score: 0.03 \t Current Score: 0.20\n",
      "Episode 83\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 84\tAverage Score: 0.03 \t Current Score: 0.20\n",
      "Episode 85\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 86\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 87\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 88\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 89\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 90\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 91\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 92\tAverage Score: 0.03 \t Current Score: 0.20\n",
      "Episode 93\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 94\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 95\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 96\tAverage Score: 0.03 \t Current Score: 0.20\n",
      "Episode 97\tAverage Score: 0.04 \t Current Score: 0.10\n",
      "Episode 98\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 99\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 100\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 101\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 102\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 103\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 104\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 105\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 106\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 107\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 108\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 109\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 110\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 111\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 112\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 113\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 114\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 115\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 116\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 117\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 118\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 119\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 120\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 121\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 122\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 123\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 124\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 125\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 126\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 127\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 128\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 129\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 130\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 131\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 132\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 133\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 134\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 135\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 136\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 137\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 138\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 139\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 140\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 141\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 142\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 143\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 144\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 145\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 146\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 147\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 148\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 149\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 150\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 151\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 152\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 153\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 154\tAverage Score: 0.02 \t Current Score: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 155\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 156\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 157\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 158\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 159\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 160\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 161\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 162\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 163\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 164\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 165\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 166\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 167\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 168\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 169\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 170\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 171\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 172\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 173\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 174\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 175\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 176\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 177\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 178\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 179\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 180\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 181\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 182\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 183\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 184\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 185\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 186\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 187\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 188\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 189\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 190\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 191\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 192\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 193\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 194\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 195\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 196\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 197\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 198\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 199\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 200\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 201\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 202\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 203\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 204\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 205\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 206\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 207\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 208\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 209\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 210\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 211\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 212\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 213\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 214\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 215\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 216\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 217\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 218\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 219\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 220\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 221\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 222\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 223\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 224\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 225\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 226\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 227\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 228\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 229\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 230\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 231\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 232\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 233\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 234\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 235\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 236\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 237\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 238\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 239\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 240\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 241\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 242\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 243\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 244\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 245\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 246\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 247\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 248\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 249\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 250\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 251\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 252\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 253\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 254\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 255\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 256\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 257\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 258\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 259\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 260\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 261\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 262\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 263\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 264\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 265\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 266\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 267\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 268\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 269\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 270\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 271\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 272\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 273\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 274\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 275\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 276\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 277\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 278\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 279\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 280\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 281\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 282\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 283\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 284\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 285\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 286\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 287\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 288\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 289\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 290\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 291\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 292\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 293\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 294\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 295\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 296\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 297\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 298\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 299\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 300\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 301\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 302\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 303\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 304\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 305\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 306\tAverage Score: 0.00 \t Current Score: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 307\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 308\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 309\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 310\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 311\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 312\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 313\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 314\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 315\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 316\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 317\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 318\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 319\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 320\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 321\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 322\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 323\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 324\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 325\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 326\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 327\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 328\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 329\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 330\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 331\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 332\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 333\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 334\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 335\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 336\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 337\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 338\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 339\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 340\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 341\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 342\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 343\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 344\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 345\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 346\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 347\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 348\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 349\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 350\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 351\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 352\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 353\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 354\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 355\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 356\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 357\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 358\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 359\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 360\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 361\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 362\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 363\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 364\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 365\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 366\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 367\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 368\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 369\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 370\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 371\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 372\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 373\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 374\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 375\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 376\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 377\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 378\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 379\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 380\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 381\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 382\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 383\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 384\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 385\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 386\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 387\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 388\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 389\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 390\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 391\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 392\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 393\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 394\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 395\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 396\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 397\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 398\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 399\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 400\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 401\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 402\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 403\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 404\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 405\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 406\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 407\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 408\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 409\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 410\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 411\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 412\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 413\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 414\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 415\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 416\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 417\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 418\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 419\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 420\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 421\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 422\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 423\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 424\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 425\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 426\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 427\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 428\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 429\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 430\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 431\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 432\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 433\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 434\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 435\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 436\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 437\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 438\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 439\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 440\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 441\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 442\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 443\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 444\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 445\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 446\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 447\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 448\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 449\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 450\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 451\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 452\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 453\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 454\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 455\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 456\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 457\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 458\tAverage Score: 0.00 \t Current Score: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 459\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 460\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 461\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 462\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 463\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 464\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 465\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 466\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 467\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 468\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 469\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 470\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 471\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 472\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 473\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 474\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 475\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 476\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 477\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 478\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 479\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 480\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 481\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 482\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 483\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 484\tAverage Score: 0.00 \t Current Score: 0.10\n",
      "Episode 485\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 486\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 487\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 488\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 489\tAverage Score: 0.00 \t Current Score: 0.10\n",
      "Episode 490\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 491\tAverage Score: 0.00 \t Current Score: 0.10\n",
      "Episode 492\tAverage Score: 0.00 \t Current Score: 0.00\n",
      "Episode 493\tAverage Score: 0.01 \t Current Score: 0.20\n",
      "Episode 494\tAverage Score: 0.01 \t Current Score: 0.00\n",
      "Episode 495\tAverage Score: 0.01 \t Current Score: 0.20\n",
      "Episode 496\tAverage Score: 0.01 \t Current Score: 0.10\n",
      "Episode 497\tAverage Score: 0.01 \t Current Score: 0.20\n",
      "Episode 498\tAverage Score: 0.02 \t Current Score: 1.20\n",
      "Episode 499\tAverage Score: 0.02 \t Current Score: 0.00\n",
      "Episode 500\tAverage Score: 0.03 \t Current Score: 0.40\n",
      "Episode 501\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 502\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 503\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 504\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 505\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 506\tAverage Score: 0.03 \t Current Score: 0.30\n",
      "Episode 507\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 508\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 509\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 510\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 511\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 512\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 513\tAverage Score: 0.03 \t Current Score: 0.10\n",
      "Episode 514\tAverage Score: 0.03 \t Current Score: 0.00\n",
      "Episode 515\tAverage Score: 0.04 \t Current Score: 0.80\n",
      "Episode 516\tAverage Score: 0.04 \t Current Score: 0.10\n",
      "Episode 517\tAverage Score: 0.04 \t Current Score: 0.10\n",
      "Episode 518\tAverage Score: 0.05 \t Current Score: 0.20\n",
      "Episode 519\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 520\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 521\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 522\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 523\tAverage Score: 0.05 \t Current Score: 0.00\n",
      "Episode 524\tAverage Score: 0.05 \t Current Score: 0.00\n",
      "Episode 525\tAverage Score: 0.05 \t Current Score: 0.00\n",
      "Episode 526\tAverage Score: 0.05 \t Current Score: 0.00\n",
      "Episode 527\tAverage Score: 0.05 \t Current Score: 0.00\n",
      "Episode 528\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 529\tAverage Score: 0.05 \t Current Score: 0.30\n",
      "Episode 530\tAverage Score: 0.05 \t Current Score: 0.10\n",
      "Episode 531\tAverage Score: 0.06 \t Current Score: 0.20\n",
      "Episode 532\tAverage Score: 0.06 \t Current Score: 0.30\n",
      "Episode 533\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 534\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 535\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 536\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 537\tAverage Score: 0.06 \t Current Score: 0.10\n",
      "Episode 538\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 539\tAverage Score: 0.06 \t Current Score: 0.10\n",
      "Episode 540\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 541\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 542\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 543\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 544\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 545\tAverage Score: 0.06 \t Current Score: 0.10\n",
      "Episode 546\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 547\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 548\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 549\tAverage Score: 0.06 \t Current Score: 0.10\n",
      "Episode 550\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 551\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 552\tAverage Score: 0.06 \t Current Score: 0.10\n",
      "Episode 553\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 554\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 555\tAverage Score: 0.06 \t Current Score: 0.00\n",
      "Episode 556\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 557\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 558\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 559\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 560\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 561\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 562\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 563\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 564\tAverage Score: 0.07 \t Current Score: 0.20\n",
      "Episode 565\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 566\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 567\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 568\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 569\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 570\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 571\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 572\tAverage Score: 0.07 \t Current Score: 0.10\n",
      "Episode 573\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 574\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 575\tAverage Score: 0.07 \t Current Score: 0.00\n",
      "Episode 576\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 577\tAverage Score: 0.08 \t Current Score: 0.00\n",
      "Episode 578\tAverage Score: 0.08 \t Current Score: 0.00\n",
      "Episode 579\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 580\tAverage Score: 0.08 \t Current Score: 0.20\n",
      "Episode 581\tAverage Score: 0.08 \t Current Score: 0.20\n",
      "Episode 582\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 583\tAverage Score: 0.08 \t Current Score: 0.00\n",
      "Episode 584\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 585\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 586\tAverage Score: 0.08 \t Current Score: 0.10\n",
      "Episode 587\tAverage Score: 0.09 \t Current Score: 0.30\n",
      "Episode 588\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 589\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 590\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 591\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 592\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 593\tAverage Score: 0.10 \t Current Score: 1.60\n",
      "Episode 594\tAverage Score: 0.10 \t Current Score: 0.10\n",
      "Episode 595\tAverage Score: 0.10 \t Current Score: 0.10\n",
      "Episode 596\tAverage Score: 0.10 \t Current Score: 0.00\n",
      "Episode 597\tAverage Score: 0.10 \t Current Score: 0.00\n",
      "Episode 598\tAverage Score: 0.09 \t Current Score: 0.20\n",
      "Episode 599\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 600\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 601\tAverage Score: 0.09 \t Current Score: 0.00\n",
      "Episode 602\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 603\tAverage Score: 0.09 \t Current Score: 0.30\n",
      "Episode 604\tAverage Score: 0.09 \t Current Score: 0.30\n",
      "Episode 605\tAverage Score: 0.09 \t Current Score: 0.10\n",
      "Episode 606\tAverage Score: 0.10 \t Current Score: 1.10\n",
      "Episode 607\tAverage Score: 0.13 \t Current Score: 2.70\n",
      "Episode 608\tAverage Score: 0.13 \t Current Score: 0.20\n",
      "Episode 609\tAverage Score: 0.13 \t Current Score: 0.00\n",
      "Episode 610\tAverage Score: 0.13 \t Current Score: 0.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 611\tAverage Score: 0.14 \t Current Score: 0.70\n",
      "Episode 612\tAverage Score: 0.14 \t Current Score: 0.10\n",
      "Episode 613\tAverage Score: 0.14 \t Current Score: 0.10\n",
      "Episode 614\tAverage Score: 0.14 \t Current Score: 0.40\n",
      "Episode 615\tAverage Score: 0.14 \t Current Score: 0.10\n",
      "Episode 616\tAverage Score: 0.14 \t Current Score: 0.10\n",
      "Episode 617\tAverage Score: 0.15 \t Current Score: 1.80\n",
      "Episode 618\tAverage Score: 0.16 \t Current Score: 0.40\n",
      "Episode 619\tAverage Score: 0.16 \t Current Score: 0.10\n",
      "Episode 620\tAverage Score: 0.16 \t Current Score: 0.90\n",
      "Episode 621\tAverage Score: 0.19 \t Current Score: 2.40\n",
      "Episode 622\tAverage Score: 0.19 \t Current Score: 0.10\n",
      "Episode 623\tAverage Score: 0.19 \t Current Score: 0.20\n",
      "Episode 624\tAverage Score: 0.21 \t Current Score: 2.50\n",
      "Episode 625\tAverage Score: 0.23 \t Current Score: 1.30\n",
      "Episode 626\tAverage Score: 0.23 \t Current Score: 0.40\n",
      "Episode 627\tAverage Score: 0.23 \t Current Score: 0.20\n",
      "Episode 628\tAverage Score: 0.23 \t Current Score: 0.20\n",
      "Episode 629\tAverage Score: 0.23 \t Current Score: 0.20\n",
      "Episode 630\tAverage Score: 0.24 \t Current Score: 0.40\n",
      "Episode 631\tAverage Score: 0.24 \t Current Score: 0.20\n",
      "Episode 632\tAverage Score: 0.24 \t Current Score: 0.40\n",
      "Episode 633\tAverage Score: 0.25 \t Current Score: 0.90\n",
      "Episode 634\tAverage Score: 0.25 \t Current Score: 0.60\n",
      "Episode 635\tAverage Score: 0.26 \t Current Score: 0.50\n",
      "Episode 636\tAverage Score: 0.26 \t Current Score: 0.40\n",
      "Episode 637\tAverage Score: 0.27 \t Current Score: 1.40\n",
      "Episode 638\tAverage Score: 0.28 \t Current Score: 0.30\n",
      "Episode 639\tAverage Score: 0.28 \t Current Score: 0.30\n",
      "Episode 640\tAverage Score: 0.28 \t Current Score: 0.40\n",
      "Episode 641\tAverage Score: 0.29 \t Current Score: 0.30\n",
      "Episode 642\tAverage Score: 0.30 \t Current Score: 0.90\n",
      "Episode 643\tAverage Score: 0.30 \t Current Score: 0.10\n",
      "Episode 644\tAverage Score: 0.35 \t Current Score: 5.20\n",
      "Episode 645\tAverage Score: 0.39 \t Current Score: 4.20\n",
      "Episode 646\tAverage Score: 0.39 \t Current Score: 0.10\n",
      "Episode 647\tAverage Score: 0.39 \t Current Score: 0.10\n",
      "Episode 648\tAverage Score: 0.39 \t Current Score: 0.10\n",
      "Episode 649\tAverage Score: 0.39 \t Current Score: 0.30\n",
      "Episode 650\tAverage Score: 0.40 \t Current Score: 0.10\n",
      "Episode 651\tAverage Score: 0.40 \t Current Score: 0.30\n",
      "Episode 652\tAverage Score: 0.40 \t Current Score: 0.10\n",
      "Episode 653\tAverage Score: 0.44 \t Current Score: 3.90\n",
      "Episode 654\tAverage Score: 0.46 \t Current Score: 1.90\n",
      "Episode 655\tAverage Score: 0.46 \t Current Score: 0.10\n",
      "Episode 656\tAverage Score: 0.47 \t Current Score: 0.90\n",
      "Episode 657\tAverage Score: 0.47 \t Current Score: 0.80\n",
      "Episode 658\tAverage Score: 0.52 \t Current Score: 5.00\n",
      "\n",
      "Environment solved in 558 episodes!\tAverage Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "from workspace_utils import active_session # Udacity workspace utility functions\n",
    "\n",
    "# run the training loop\n",
    "with active_session():\n",
    "    scores, avgs = ddpg(n_episodes=2000, max_t=1000, start_steps = 100, learn_frequency = 10, learn_count = 5, random_seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the moving average of the training. The environment is solved once it reaches 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9348698d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='moving avg by last 100')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scores returned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe932ca3e80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "x = np.arange(len(scores))\n",
    "fig.suptitle('Score progress')\n",
    "ax1.plot(x, scores)\n",
    "ax2.plot(x, avgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the environment once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Command-Line usage parser\n",
    "The following is parser for the command line interface for the DDPG solving the unity environment. \n",
    "<b>Not to be executed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_episodes', type=int, default=2000)\n",
    "    parser.add_argument('--max_t', type=int, default=1000)\n",
    "    parser.add_argument('--start_steps', type=int, default=100)\n",
    "    parser.add_argument('--learn_frequency', type=int, default=10)\n",
    "    parser.add_argument('--learn_count', type=int, default=5)\n",
    "    parser.add_argument('--random_seed', type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    ddpg(n_episodes = args.n_episodes, max_t = args.max_t, start_steps = args.start_steps, \\\n",
    "         learn_frequency = args.learn_frequency, learn_count = args.learn_count, random_seed = args.random_seed)\n",
    "env.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Generate script from the notebook\n",
    "Throughout this notebook you've been seeing cells marked with ```#export```. The script below picks cells that are marked and append them into python script. This is adopted from fast-ai's deep learning course practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Report.ipynb to nb_Report.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py Report.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, `nb_Report.py` script should have been generated in your workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Run the script from the command-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python nb_Report.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusions and Future Work\n",
    "\n",
    "#### Summary\n",
    "\n",
    "We've just learned to play tennis in Unity Environment, yay! Our DDPG agent proved to be versalite and able to solve the environment during repeated trials, and sometimes the agent achieved score over 5. This, by itself, proves that DDPG agent is able to solve such continuous control scenarios.\n",
    "\n",
    "Moreover, we made the agent play with itself and learn. I'm sure you can see how strong DDPG algorithm is. There are variants like Multi-Agent DDPG called MADDPG especially suited for multi agent settings, but a single DDPG was enough for the task. Lastly, note that agent received its own local observation instead of global observation, enabling it to play any side of the tennis environment.\n",
    "\n",
    "DDPG's ability to deal with completely continuous setting makes it valuable in real-world scenario the **robotics**. In real-world, everything is continuous, therefore DDPG is something to try on.\n",
    "\n",
    "And, as always, you are most welcome to play around with the hyperparameters to make it even more efficient.\n",
    "\n",
    "### Future work\n",
    "\n",
    "This was DDPG agent with slight hyperparameters and training modifications. There are two ways we can go from here. First of all, we could try to solve even harder environment or even better, try the algorithm with robots! While I don't have any robots that I could use, I will direct you to harder Unity enviroment, [the Soccer](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md). You are encouraged to follow their setup guide and tryout the agent we used here.\n",
    "\n",
    "Secondly, while DDPG can achieve great performance sometimes, it is frequently brittle with respect to hyperparameters and other kinds of tuning. A common failure mode for DDPG is that the learned Q-function begins to dramatically overestimate Q-values, which then leads to the policy breaking, because it exploits the errors in the Q-function. There have been numerous improvements since 2015 when DDPG was first introduced. I encourage you to check out [(TD3)Twin Delayed DDPG](https://arxiv.org/abs/1802.09477) and [(D4PG) Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617). Also, you can try [MADDPG](https://arxiv.org/pdf/1706.02275.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
